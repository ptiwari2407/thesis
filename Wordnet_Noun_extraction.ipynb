{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82115\n"
     ]
    }
   ],
   "source": [
    "allSynsets = list(wn.all_synsets(wn.NOUN))\n",
    "print(len(allSynsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and for all these synsets, we intend to generate all the lemmas associated \n",
    "# with it\n",
    "# SO we get all hyponyms associated with these sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_allSynsets = allSynsets[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('abstraction.n.06'),\n",
       " Synset('thing.n.12'),\n",
       " Synset('object.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('congener.n.03'),\n",
       " Synset('living_thing.n.01'),\n",
       " Synset('organism.n.01'),\n",
       " Synset('benthos.n.02'),\n",
       " Synset('dwarf.n.03'),\n",
       " Synset('heterotroph.n.01'),\n",
       " Synset('parent.n.02'),\n",
       " Synset('life.n.10'),\n",
       " Synset('biont.n.01'),\n",
       " Synset('cell.n.02'),\n",
       " Synset('causal_agent.n.01'),\n",
       " Synset('person.n.01'),\n",
       " Synset('animal.n.01'),\n",
       " Synset('plant.n.02'),\n",
       " Synset('native.n.03'),\n",
       " Synset('natural_object.n.01'),\n",
       " Synset('substance.n.01'),\n",
       " Synset('substance.n.07'),\n",
       " Synset('matter.n.03'),\n",
       " Synset('food.n.01'),\n",
       " Synset('nutrient.n.02'),\n",
       " Synset('artifact.n.01'),\n",
       " Synset('article.n.02'),\n",
       " Synset('psychological_feature.n.01'),\n",
       " Synset('cognition.n.01'),\n",
       " Synset('motivation.n.01'),\n",
       " Synset('attribute.n.02'),\n",
       " Synset('state.n.02'),\n",
       " Synset('feeling.n.01'),\n",
       " Synset('location.n.01'),\n",
       " Synset('shape.n.02'),\n",
       " Synset('time.n.05'),\n",
       " Synset('space.n.01'),\n",
       " Synset('absolute_space.n.01')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_allSynsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(sub_allSynsets))\n",
    "syn_group = []\n",
    "syn_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlist(m):\n",
    "    q = []\n",
    "    for x in m:\n",
    "        if(type(x) is list):\n",
    "            for y in x:\n",
    "                q.append(y)\n",
    "            continue\n",
    "        q.append(x)\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in sub_allSynsets:\n",
    "    syn_group.append(elem.name())\n",
    "syn_group = syn_group[7:10]\n",
    "z = ['dog.n.01','frump.n.01','benthos.n.01', 'access.n.04']\n",
    "syn_group.append(z)\n",
    "syn_group = unlist(syn_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['living_thing.n.01',\n",
       " 'organism.n.01',\n",
       " 'benthos.n.02',\n",
       " 'dog.n.01',\n",
       " 'frump.n.01',\n",
       " 'benthos.n.01',\n",
       " 'access.n.04']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 4, 3: 2, 4: 1, 5: 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [2,3,3,2,4,5,2,2,5]\n",
    "d = {x:a.count(x) for x in a}\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82115\n",
      "['entity']\n",
      "***********************************\n",
      "['physical_entity']\n",
      "***********************************\n",
      "['abstraction', 'abstract_entity']\n",
      "***********************************\n",
      "['thing']\n",
      "***********************************\n",
      "['object', 'physical_object']\n",
      "***********************************\n",
      "['whole', 'unit']\n",
      "***********************************\n",
      "['congener']\n",
      "***********************************\n",
      "['living_thing', 'animate_thing']\n",
      "***********************************\n",
      "['organism', 'being']\n",
      "***********************************\n",
      "['benthos']\n",
      "***********************************\n"
     ]
    }
   ],
   "source": [
    "# Logic 1 : Access only the lemma_names of the synset itself\n",
    "syn_group = []\n",
    "syn_dict = dict()\n",
    "synGroup_length = []\n",
    "for elem in allSynsets:\n",
    "    syn_group.append(elem.name())\n",
    "\n",
    "for elem in syn_group:\n",
    "    word = wn.synset(elem)\n",
    "    syn_dict[elem] = word.lemma_names()\n",
    "    synGroup_length.append(len(syn_dict[elem]))\n",
    "\n",
    "print(len(syn_group))\n",
    "arr = np.array(synGroup_length)\n",
    "(unique, counts) = np.unique(arr, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "for elem in syn_group[0:10]:\n",
    "    print(syn_dict[elem])\n",
    "    print(\"***********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity.n.01\n",
      "physical_entity.n.01\n",
      "abstraction.n.06\n",
      "thing.n.12\n",
      "object.n.01\n",
      "whole.n.02\n",
      "congener.n.03\n",
      "living_thing.n.01\n",
      "organism.n.01\n",
      "benthos.n.02\n",
      "dwarf.n.03\n",
      "heterotroph.n.01\n",
      "parent.n.02\n",
      "life.n.10\n",
      "biont.n.01\n",
      "cell.n.02\n",
      "causal_agent.n.01\n",
      "person.n.01\n",
      "animal.n.01\n",
      "plant.n.02\n",
      "native.n.03\n",
      "natural_object.n.01\n",
      "substance.n.01\n",
      "substance.n.07\n",
      "matter.n.03\n",
      "food.n.01\n",
      "nutrient.n.02\n",
      "artifact.n.01\n",
      "article.n.02\n",
      "psychological_feature.n.01\n",
      "cognition.n.01\n",
      "motivation.n.01\n",
      "attribute.n.02\n",
      "state.n.02\n",
      "feeling.n.01\n",
      "location.n.01\n",
      "shape.n.02\n",
      "time.n.05\n",
      "space.n.01\n",
      "absolute_space.n.01\n"
     ]
    }
   ],
   "source": [
    "syn_group = []\n",
    "syn_dict = dict()\n",
    "synGroup_length = []\n",
    "for elem in sub_allSynsets:\n",
    "    syn_group.append(elem.name())\n",
    "    print(elem.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82115\n",
      "[[    1 33882]\n",
      " [    2 22896]\n",
      " [    3  8985]\n",
      " [    4  4512]\n",
      " [    5  2523]\n",
      " [    6  1701]\n",
      " [    7  1232]\n",
      " [    8   905]\n",
      " [    9   704]\n",
      " [   10   550]\n",
      " [   11   446]\n",
      " [   12   406]\n",
      " [   13   320]\n",
      " [   14   281]\n",
      " [   15   271]\n",
      " [   16   203]\n",
      " [   17   211]\n",
      " [   18   152]\n",
      " [   19   155]\n",
      " [   20   130]\n",
      " [   21   110]\n",
      " [   22   103]\n",
      " [   23    97]\n",
      " [   24    86]\n",
      " [   25    91]\n",
      " [   26    65]\n",
      " [   27    68]\n",
      " [   28    57]\n",
      " [   29    52]\n",
      " [   30    34]\n",
      " [   31    38]\n",
      " [   32    35]\n",
      " [   33    33]\n",
      " [   34    35]\n",
      " [   35    32]\n",
      " [   36    33]\n",
      " [   37    23]\n",
      " [   38    34]\n",
      " [   39    24]\n",
      " [   40    34]\n",
      " [   41    18]\n",
      " [   42    20]\n",
      " [   43    21]\n",
      " [   44    19]\n",
      " [   45    21]\n",
      " [   46    18]\n",
      " [   47    19]\n",
      " [   48    22]\n",
      " [   49    15]\n",
      " [   50     7]\n",
      " [   51    13]\n",
      " [   52    10]\n",
      " [   53    10]\n",
      " [   54    15]\n",
      " [   55    11]\n",
      " [   56    11]\n",
      " [   57    13]\n",
      " [   58     5]\n",
      " [   59     9]\n",
      " [   60     8]\n",
      " [   61    11]\n",
      " [   62     5]\n",
      " [   63     8]\n",
      " [   64     2]\n",
      " [   65     5]\n",
      " [   66     8]\n",
      " [   67     5]\n",
      " [   68     6]\n",
      " [   69     6]\n",
      " [   70     4]\n",
      " [   71     5]\n",
      " [   72     3]\n",
      " [   73     5]\n",
      " [   74     6]\n",
      " [   75     9]\n",
      " [   76     7]\n",
      " [   77     3]\n",
      " [   78     3]\n",
      " [   79     4]\n",
      " [   80     3]\n",
      " [   81     3]\n",
      " [   82     3]\n",
      " [   83     1]\n",
      " [   84     6]\n",
      " [   85     1]\n",
      " [   86     1]\n",
      " [   87     7]\n",
      " [   88     4]\n",
      " [   90     1]\n",
      " [   91     6]\n",
      " [   92     2]\n",
      " [   93     2]\n",
      " [   94     3]\n",
      " [   95     1]\n",
      " [   96     7]\n",
      " [   97     1]\n",
      " [   99     5]\n",
      " [  100     3]\n",
      " [  101     2]\n",
      " [  102     2]\n",
      " [  105     2]\n",
      " [  107     2]\n",
      " [  108     3]\n",
      " [  110     3]\n",
      " [  111     1]\n",
      " [  112     1]\n",
      " [  114     1]\n",
      " [  115     1]\n",
      " [  116     4]\n",
      " [  117     1]\n",
      " [  119     2]\n",
      " [  121     2]\n",
      " [  122     1]\n",
      " [  123     2]\n",
      " [  124     1]\n",
      " [  126     1]\n",
      " [  127     2]\n",
      " [  128     2]\n",
      " [  131     1]\n",
      " [  132     3]\n",
      " [  133     2]\n",
      " [  135     1]\n",
      " [  136     2]\n",
      " [  137     1]\n",
      " [  142     1]\n",
      " [  143     2]\n",
      " [  144     1]\n",
      " [  145     1]\n",
      " [  149     1]\n",
      " [  154     1]\n",
      " [  155     1]\n",
      " [  156     1]\n",
      " [  159     1]\n",
      " [  163     1]\n",
      " [  165     1]\n",
      " [  166     1]\n",
      " [  174     1]\n",
      " [  178     1]\n",
      " [  179     1]\n",
      " [  181     1]\n",
      " [  187     1]\n",
      " [  188     1]\n",
      " [  192     2]\n",
      " [  193     1]\n",
      " [  195     1]\n",
      " [  197     1]\n",
      " [  198     1]\n",
      " [  200     1]\n",
      " [  211     1]\n",
      " [  212     1]\n",
      " [  215     1]\n",
      " [  220     1]\n",
      " [  222     1]\n",
      " [  226     1]\n",
      " [  234     1]\n",
      " [  238     2]\n",
      " [  248     1]\n",
      " [  259     1]\n",
      " [  266     2]\n",
      " [  270     1]\n",
      " [  280     1]\n",
      " [  288     1]\n",
      " [  292     1]\n",
      " [  295     2]\n",
      " [  316     1]\n",
      " [  317     1]\n",
      " [  321     1]\n",
      " [  328     1]\n",
      " [  354     1]\n",
      " [  358     1]\n",
      " [  370     1]\n",
      " [  388     1]\n",
      " [  401     1]\n",
      " [  403     1]\n",
      " [  430     1]\n",
      " [  443     1]\n",
      " [  503     1]\n",
      " [  563     1]\n",
      " [  572     1]\n",
      " [  585     1]\n",
      " [  594     1]\n",
      " [  645     1]\n",
      " [  697     1]\n",
      " [  718     1]\n",
      " [  779     1]\n",
      " [  804     1]\n",
      " [ 1067     1]\n",
      " [ 1093     1]\n",
      " [ 1697     1]]\n"
     ]
    }
   ],
   "source": [
    "# Logic 2 : Access one level down to hyponym and collect them\n",
    "hypo = lambda s: s.hyponyms()\n",
    "hyper = lambda s: s.hypernyms()\n",
    "syn_group = []\n",
    "syn_dict = dict()\n",
    "synGroup_length = []\n",
    "for elem in allSynsets:\n",
    "    syn_group.append(elem.name())\n",
    "\n",
    "for elem in syn_group:\n",
    "    word = wn.synset(elem)\n",
    "    syn_dict[elem] = word.lemma_names()\n",
    "    hypo_list = list(set(word.closure(hypo, depth=1)))\n",
    "    \n",
    "    for item in hypo_list:\n",
    "        temp =[]\n",
    "        name = item.name()\n",
    "        temp = wn.synset(name).lemma_names()\n",
    "        syn_dict[elem].append(temp)  \n",
    "    syn_dict[elem] = unlist(syn_dict[elem])\n",
    "    synGroup_length.append(len(syn_dict[elem]))\n",
    "    \n",
    "print(len(synGroup_length))\n",
    "arr = np.array(synGroup_length)\n",
    "(unique, counts) = np.unique(arr, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benthos', 'organism', 'being', 'polymorph', 'utterer', 'vocalizer', 'vocaliser', 'mutant', 'mutation', 'variation', 'sport', 'denizen', 'saprobe', 'commensal', 'relict', 'hybrid', 'crossbreed', 'cross', 'animalcule', 'animalculum', 'benthos', 'myrmecophile', 'prokaryote', 'procaryote', 'conspecific', 'native', 'parasite', 'carrier', 'postdiluvian', 'polyploid', 'plant', 'flora', 'plant_life', 'atavist', 'throwback', 'anaerobe', 'animal', 'animate_being', 'beast', 'brute', 'creature', 'fauna', 'heteroploid', 'aerobe', 'fungus', 'mascot', 'clone', 'clon', 'individual', 'katharobe', 'plankton', 'diploid', 'parent', 'person', 'individual', 'someone', 'somebody', 'mortal', 'soul', 'amphidiploid', 'dwarf', 'host', 'stander', 'haploid', 'recombinant', 'eukaryote', 'eucaryote', 'microorganism', 'micro-organism', 'nekton', 'sitter', 'zooid', 'saprophyte', 'saprophytic_organism', 'relative', 'congener', 'congenator', 'congeneric', 'nonvascular_organism', 'heterotroph']\n",
      "['frump', 'dog', 'unpleasant_woman', 'disagreeable_woman', 'bag', 'old_bag', 'shrew', 'termagant', 'cow', 'she-devil', 'frump', 'dog', 'dragon', 'tartar', 'vixen', 'harpy', 'hellcat']\n",
      "['benthos', 'benthic_division', 'benthonic_zone', 'biogeographical_region', 'benthos', 'benthic_division', 'benthonic_zone']\n",
      "['access', 'access_code', 'back_door', 'backdoor', 'code', 'access', 'access_code', 'color_code', 'area_code', 'cipher', 'cypher', 'cryptograph', 'secret_code', 'Morse', 'Morse_code', 'international_Morse_code', 'bar_code', 'Universal_Product_Code', 'ZIP_code', 'ZIP', 'postcode', 'postal_code']\n"
     ]
    }
   ],
   "source": [
    "# Logic 3: \n",
    "# !!! ACHTUNG \n",
    "# do not run this block on this computer \n",
    "hypo = lambda s: s.hyponyms()\n",
    "hyper = lambda s: s.hypernyms()\n",
    "\n",
    "\"\"\"\n",
    "# the following generalisation applies all the hyponyms embodies the general idea \n",
    "# so, we can get upto 20 depths possible \n",
    "# But the hypernym meaning coincide to a greater degree only one/two depth up and no \n",
    "# more, so if after inclusion of hyponym, the list does not grows more than 5\n",
    "# we seek answers from Hypernym structure\n",
    "# The data-collection from word-net itself is gathered to match the represenation of \n",
    "# of word-net itself\n",
    "\"\"\"\n",
    "\n",
    "# for elem in allSynsets:\n",
    "#     syn_group.append(elem.name())\n",
    "for elem in syn_group:\n",
    "    word = wn.synset(elem)\n",
    "    syn_dict[elem] = word.lemma_names()\n",
    "    syn_dict[elem] = unlist(syn_dict[elem])\n",
    "    hypo_list = list(set(word.closure(hypo, depth=20)))\n",
    "    hypo_list = hypo_list[0:10]\n",
    "    \n",
    "    for item in hypo_list:\n",
    "        temp =[]\n",
    "        name = item.name()\n",
    "        temp = wn.synset(name).lemma_names()\n",
    "        syn_dict[elem].append(temp)  \n",
    "    syn_dict[elem] = unlist(syn_dict[elem])\n",
    "    \n",
    "    a=len(syn_dict[elem])\n",
    "    if(a>5):\n",
    "        continue\n",
    "    \n",
    "    hyper_list = list(set(word.closure(hyper, depth=1)))\n",
    "    \n",
    "    for item in hyper_list:\n",
    "        temp =[]\n",
    "        name = item.name()\n",
    "        temp = wn.synset(name).lemma_names()\n",
    "        syn_dict[elem].append(temp)  \n",
    "    \n",
    "    \n",
    "    for item in hyper_list:\n",
    "        name = item.name()\n",
    "        w1 = wn.synset(name)\n",
    "        w1_list = list(set(w1.closure(hypo, depth=1)))\n",
    "        for id in w1_list:\n",
    "          temp=[]\n",
    "          temp.append(id.lemma_names())\n",
    "          syn_dict[elem].append(temp)\n",
    "        # syn_dict[elem] = unlist(syn_dict[elem])\n",
    "    syn_dict[elem] = unlist(syn_dict[elem])\n",
    "    syn_dict[elem] = unlist(syn_dict[elem])\n",
    "    syn_dict[elem] = unlist(syn_dict[elem])\n",
    "    print(syn_dict[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['organism', 'being']\n"
     ]
    }
   ],
   "source": [
    "# ? first we see all the hyponyms of the self\n",
    "o = wn.synset('organism.n.01').lemma_names()\n",
    "print(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frump\n",
      "dog\n",
      "['frump', 'dog']\n"
     ]
    }
   ],
   "source": [
    "w1 = wn.synset('frump.n.01')\n",
    "x =[]\n",
    "for l in w1.lemmas():\n",
    "    print(l.name())\n",
    "    x.append(l.name())\n",
    "    \n",
    "print(x)\n",
    "# print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('shrew.n.01')\n",
      "shrew.n.01 a scolding nagging bad-tempered woman\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['shrew.n.01']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'termagant'\n",
    "syn_group = []\n",
    "syn_dict = dict()\n",
    "for elem in wn.synsets(word):\n",
    "    syn_group.append(elem.name())\n",
    "    print(elem)\n",
    "for elem in syn_group:\n",
    "    syn_dict[elem]= wn.synset(elem).definition()\n",
    "#     print(elem.hypernyms())\n",
    "    print(elem,syn_dict[elem])\n",
    "syn_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('yenta.n.01'), Synset('virago.n.01')]\n",
      "[Synset('unpleasant_woman.n.01')]\n",
      "['yenta']\n",
      "['virago']\n"
     ]
    }
   ],
   "source": [
    "word = wn.synset(elem)\n",
    "hypo_list = list(set(word.closure(hypo, depth=20)))\n",
    "hyper_list = list(set(word.closure(hyper, depth=1)))\n",
    "print(hypo_list)\n",
    "print(hyper_list)\n",
    "for item in hypo_list:\n",
    "    temp =[]\n",
    "    name = item.name()\n",
    "    temp = wn.synset(name).lemma_names()\n",
    "    print(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['access', 'area', 'apartment', 'book', 'business', 'audience', 'bunch', 'case', 'cause', 'child', 'company', 'communication', 'country', 'combination', 'conclusion', 'contribution', 'day', 'design', 'feature', 'dealer', 'demand', 'discussion', 'development', 'environment', 'fat', 'fact', 'family', 'government', 'group', 'hand', 'home', 'happiness', 'income', 'investment', 'indication', 'intention', 'job', 'kayak', 'king', 'life', 'lake', 'love', 'lot', 'man', 'money', 'month', 'mother', 'night', 'number', 'offer', 'people', 'place', 'problem', 'photograph', 'priority', 'question', 'right', 'reality', 'relation', 'revolution', 'replacement', 'resource', 'recommendation', 'room', 'school', 'state', 'story', 'student', 'surgery', 'sympathy', 'system', 'tension', 'thing', 'thought', 'time', 'training', 'universe', 'victim', 'way', 'wealth', 'woman', 'word', 'work', 'world', 'year', 'inside', 'outside', 'medium', 'item', 'average', 'feeling', 'savings', 'edge', 'evidence', 'street', 'drop', 'substance', 'detail', 'agent']\n"
     ]
    }
   ],
   "source": [
    "noun = []\n",
    "filename = \"data/nouns.txt\"\n",
    "with open(filename, 'r') as f:\n",
    "    nouns= [line.strip() for line in f]\n",
    "nouns = nouns[1:len(nouns)]\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "access\n",
      "['entree.n.02', 'access.n.02', 'access.n.03', 'access.n.04', 'access.n.05', 'access.n.06']\n",
      "entree.n.02 ['entree', 'access', 'accession', 'admission', 'admittance']\n",
      "access.n.02 ['access']\n",
      "access.n.03 ['access', 'approach']\n",
      "access.n.04 ['access', 'access_code']\n",
      "access.n.05 ['access', 'memory_access']\n",
      "access.n.06 ['access']\n",
      "area\n",
      "['area.n.01', 'area.n.02', 'area.n.03', 'sphere.n.01', 'area.n.05', 'area.n.06']\n",
      "area.n.01 ['area', 'country']\n",
      "area.n.02 ['area']\n",
      "area.n.03 ['area', 'region']\n",
      "sphere.n.01 ['sphere', 'domain', 'area', 'orbit', 'field', 'arena']\n",
      "area.n.05 ['area']\n",
      "area.n.06 ['area', 'expanse', 'surface_area']\n",
      "apartment\n",
      "['apartment.n.01']\n",
      "apartment.n.01 ['apartment', 'flat']\n",
      "book\n",
      "['book.n.01', 'book.n.02', 'record.n.05', 'script.n.01', 'ledger.n.01', 'book.n.06', 'book.n.07', 'koran.n.01', 'bible.n.01', 'book.n.10', 'book.n.11']\n",
      "book.n.01 ['book']\n",
      "book.n.02 ['book', 'volume']\n",
      "record.n.05 ['record', 'record_book', 'book']\n",
      "script.n.01 ['script', 'book', 'playscript']\n",
      "ledger.n.01 ['ledger', 'leger', 'account_book', 'book_of_account', 'book']\n",
      "book.n.06 ['book']\n",
      "book.n.07 ['book', 'rule_book']\n",
      "koran.n.01 ['Koran', 'Quran', \"al-Qur'an\", 'Book']\n",
      "bible.n.01 ['Bible', 'Christian_Bible', 'Book', 'Good_Book', 'Holy_Scripture', 'Holy_Writ', 'Scripture', 'Word_of_God', 'Word']\n",
      "book.n.10 ['book']\n",
      "book.n.11 ['book']\n",
      "business\n",
      "['business.n.01', 'commercial_enterprise.n.02', 'occupation.n.01', 'business.n.04', 'business.n.05', 'business.n.06', 'business.n.07', 'clientele.n.01', 'business.n.09']\n",
      "business.n.01 ['business', 'concern', 'business_concern', 'business_organization', 'business_organisation']\n",
      "commercial_enterprise.n.02 ['commercial_enterprise', 'business_enterprise', 'business']\n",
      "occupation.n.01 ['occupation', 'business', 'job', 'line_of_work', 'line']\n",
      "business.n.04 ['business']\n",
      "business.n.05 ['business']\n",
      "business.n.06 ['business']\n",
      "business.n.07 ['business', 'business_sector']\n",
      "clientele.n.01 ['clientele', 'patronage', 'business']\n",
      "business.n.09 ['business', 'stage_business', 'byplay']\n",
      "audience\n",
      "['audience.n.01', 'audience.n.02', 'hearing.n.02', 'consultation.n.01']\n",
      "audience.n.01 ['audience']\n",
      "audience.n.02 ['audience']\n",
      "hearing.n.02 ['hearing', 'audience']\n",
      "consultation.n.01 ['consultation', 'audience', 'interview']\n",
      "bunch\n",
      "['bunch.n.01', 'crowd.n.02', 'bunch.n.03']\n",
      "bunch.n.01 ['bunch', 'clump', 'cluster', 'clustering']\n",
      "crowd.n.02 ['crowd', 'crew', 'gang', 'bunch']\n",
      "bunch.n.03 ['bunch', 'lot', 'caboodle']\n",
      "case\n",
      "['case.n.01', 'event.n.02', 'lawsuit.n.01', 'case.n.04', 'case.n.05', 'case.n.06', 'subject.n.06', 'case.n.08', 'case.n.09', 'case.n.10', 'case.n.11', 'case.n.12', 'character.n.05', 'font.n.01', 'sheath.n.02', 'shell.n.08', 'casing.n.03', 'case.n.18', 'case.n.19', 'case.n.20']\n",
      "case.n.01 ['case', 'instance', 'example']\n",
      "event.n.02 ['event', 'case']\n",
      "lawsuit.n.01 ['lawsuit', 'suit', 'case', 'cause', 'causa']\n",
      "case.n.04 ['case']\n",
      "case.n.05 ['case']\n",
      "case.n.06 ['case']\n",
      "subject.n.06 ['subject', 'case', 'guinea_pig']\n",
      "case.n.08 ['case']\n",
      "case.n.09 ['case']\n",
      "case.n.10 ['case', 'caseful']\n",
      "case.n.11 ['case', 'grammatical_case']\n",
      "case.n.12 ['case']\n",
      "character.n.05 ['character', 'eccentric', 'type', 'case']\n",
      "font.n.01 ['font', 'fount', 'typeface', 'face', 'case']\n",
      "sheath.n.02 ['sheath', 'case']\n",
      "shell.n.08 ['shell', 'case', 'casing']\n",
      "casing.n.03 ['casing', 'case']\n",
      "case.n.18 ['case', \"compositor's_case\", \"typesetter's_case\"]\n",
      "case.n.19 ['case', 'pillowcase', 'slip', 'pillow_slip']\n",
      "case.n.20 ['case', 'display_case', 'showcase', 'vitrine']\n",
      "cause\n",
      "['cause.n.01', 'cause.n.02', 'campaign.n.02', 'causal_agent.n.01', 'lawsuit.n.01']\n",
      "cause.n.01 ['cause']\n",
      "cause.n.02 ['cause', 'reason', 'grounds']\n",
      "campaign.n.02 ['campaign', 'cause', 'crusade', 'drive', 'movement', 'effort']\n",
      "causal_agent.n.01 ['causal_agent', 'cause', 'causal_agency']\n",
      "lawsuit.n.01 ['lawsuit', 'suit', 'case', 'cause', 'causa']\n",
      "child\n",
      "['child.n.01', 'child.n.02', 'child.n.03', 'child.n.04']\n",
      "child.n.01 ['child', 'kid', 'youngster', 'minor', 'shaver', 'nipper', 'small_fry', 'tiddler', 'tike', 'tyke', 'fry', 'nestling']\n",
      "child.n.02 ['child', 'kid']\n",
      "child.n.03 ['child', 'baby']\n",
      "child.n.04 ['child']\n",
      "company\n",
      "['company.n.01', 'company.n.02', 'company.n.03', 'company.n.04', 'caller.n.01', 'company.n.06', 'party.n.03', \"ship's_company.n.01\", 'company.n.09']\n",
      "company.n.01 ['company']\n",
      "company.n.02 ['company']\n",
      "company.n.03 ['company', 'companionship', 'fellowship', 'society']\n",
      "company.n.04 ['company', 'troupe']\n",
      "caller.n.01 ['caller', 'company']\n",
      "company.n.06 ['company']\n",
      "party.n.03 ['party', 'company']\n",
      "ship's_company.n.01 [\"ship's_company\", 'company']\n",
      "company.n.09 ['company']\n",
      "communication\n",
      "['communication.n.01', 'communication.n.02', 'communication.n.03']\n",
      "communication.n.01 ['communication', 'communicating']\n",
      "communication.n.02 ['communication']\n",
      "communication.n.03 ['communication']\n",
      "country\n",
      "['state.n.04', 'country.n.02', 'nation.n.02', 'country.n.04', 'area.n.01']\n",
      "state.n.04 ['state', 'nation', 'country', 'land', 'commonwealth', 'res_publica', 'body_politic']\n",
      "country.n.02 ['country', 'state', 'land']\n",
      "nation.n.02 ['nation', 'land', 'country']\n",
      "country.n.04 ['country', 'rural_area']\n",
      "area.n.01 ['area', 'country']\n",
      "combination\n",
      "['combination.n.01', 'combination.n.02', 'combination.n.03', 'combination.n.04', 'combination.n.05', 'combination.n.06', 'combination.n.07']\n",
      "combination.n.01 ['combination']\n",
      "combination.n.02 ['combination']\n",
      "combination.n.03 ['combination']\n",
      "combination.n.04 ['combination']\n",
      "combination.n.05 ['combination']\n",
      "combination.n.06 ['combination']\n",
      "combination.n.07 ['combination', 'combining', 'compounding']\n",
      "conclusion\n",
      "['decision.n.02', 'conclusion.n.02', 'stopping_point.n.01', 'ending.n.04', 'conclusion.n.05', 'termination.n.05', 'conclusion.n.07', 'conclusion.n.08', 'decision.n.01']\n",
      "decision.n.02 ['decision', 'determination', 'conclusion']\n",
      "conclusion.n.02 ['conclusion']\n",
      "stopping_point.n.01 ['stopping_point', 'finale', 'finis', 'finish', 'last', 'conclusion', 'close']\n",
      "ending.n.04 ['ending', 'conclusion', 'finish']\n",
      "conclusion.n.05 ['conclusion', 'ratiocination']\n",
      "termination.n.05 ['termination', 'ending', 'conclusion']\n",
      "conclusion.n.07 ['conclusion']\n",
      "conclusion.n.08 ['conclusion', 'end', 'close', 'closing', 'ending']\n",
      "decision.n.01 ['decision', 'determination', 'conclusion']\n",
      "contribution\n",
      "['contribution.n.01', 'contribution.n.02', 'contribution.n.03', 'contribution.n.04', 'contribution.n.05']\n",
      "contribution.n.01 ['contribution', 'part', 'share']\n",
      "contribution.n.02 ['contribution', 'donation']\n",
      "contribution.n.03 ['contribution', 'donation']\n",
      "contribution.n.04 ['contribution']\n",
      "contribution.n.05 ['contribution']\n",
      "day\n",
      "['day.n.01', 'day.n.02', 'day.n.03', 'day.n.04', 'day.n.05', 'day.n.06', 'day.n.07', 'sidereal_day.n.01', 'day.n.09', 'day.n.10']\n",
      "day.n.01 ['day', 'twenty-four_hours', 'twenty-four_hour_period', '24-hour_interval', 'solar_day', 'mean_solar_day']\n",
      "day.n.02 ['day']\n",
      "day.n.03 ['day']\n",
      "day.n.04 ['day', 'daytime', 'daylight']\n",
      "day.n.05 ['day']\n",
      "day.n.06 ['day']\n",
      "day.n.07 ['day']\n",
      "sidereal_day.n.01 ['sidereal_day', 'day']\n",
      "day.n.09 ['day']\n",
      "day.n.10 ['Day', 'Clarence_Day', 'Clarence_Shepard_Day_Jr.']\n",
      "design\n",
      "['design.n.01', 'design.n.02', 'blueprint.n.01', 'design.n.04', 'purpose.n.01', 'design.n.06', 'invention.n.01']\n",
      "design.n.01 ['design', 'designing']\n",
      "design.n.02 ['design', 'plan']\n",
      "blueprint.n.01 ['blueprint', 'design', 'pattern']\n",
      "design.n.04 ['design', 'pattern', 'figure']\n",
      "purpose.n.01 ['purpose', 'intent', 'intention', 'aim', 'design']\n",
      "design.n.06 ['design']\n",
      "invention.n.01 ['invention', 'innovation', 'excogitation', 'conception', 'design']\n",
      "feature\n",
      "['feature.n.01', 'feature.n.02', 'feature.n.03', 'feature.n.04', 'feature_of_speech.n.01', 'feature.n.06']\n",
      "feature.n.01 ['feature', 'characteristic']\n",
      "feature.n.02 ['feature', 'lineament']\n",
      "feature.n.03 ['feature', 'feature_film']\n",
      "feature.n.04 ['feature', 'feature_article']\n",
      "feature_of_speech.n.01 ['feature_of_speech', 'feature']\n",
      "feature.n.06 ['feature']\n",
      "dealer\n",
      "['trader.n.01', 'dealer.n.02', 'dealer.n.03', 'principal.n.06', 'dealer.n.05']\n",
      "trader.n.01 ['trader', 'bargainer', 'dealer', 'monger']\n",
      "dealer.n.02 ['dealer']\n",
      "dealer.n.03 ['dealer']\n",
      "principal.n.06 ['principal', 'dealer']\n",
      "dealer.n.05 ['dealer']\n",
      "demand\n",
      "['demand.n.01', 'demand.n.02', 'requirement.n.01', 'demand.n.04', 'need.n.01']\n",
      "demand.n.01 ['demand']\n",
      "demand.n.02 ['demand']\n",
      "requirement.n.01 ['requirement', 'demand']\n",
      "demand.n.04 ['demand']\n",
      "need.n.01 ['need', 'demand']\n",
      "discussion\n",
      "['discussion.n.01', 'discussion.n.02']\n",
      "discussion.n.01 ['discussion', 'treatment', 'discourse']\n",
      "discussion.n.02 ['discussion', 'give-and-take', 'word']\n",
      "development\n",
      "['development.n.01', 'development.n.02', 'growth.n.01', 'development.n.04', 'exploitation.n.01', 'development.n.06', 'development.n.07', 'development.n.08', 'development.n.09']\n",
      "development.n.01 ['development']\n",
      "development.n.02 ['development', 'evolution']\n",
      "growth.n.01 ['growth', 'growing', 'maturation', 'development', 'ontogeny', 'ontogenesis']\n",
      "development.n.04 ['development']\n",
      "exploitation.n.01 ['exploitation', 'development']\n",
      "development.n.06 ['development']\n",
      "development.n.07 ['development']\n",
      "development.n.08 ['development', 'developing']\n",
      "development.n.09 ['development']\n",
      "environment\n",
      "['environment.n.01', 'environment.n.02']\n",
      "environment.n.01 ['environment']\n",
      "environment.n.02 ['environment', 'environs', 'surroundings', 'surround']\n",
      "fat\n",
      "['fat.n.01', 'adipose_tissue.n.01', 'fatness.n.01']\n",
      "fat.n.01 ['fat']\n",
      "adipose_tissue.n.01 ['adipose_tissue', 'fat', 'fatty_tissue']\n",
      "fatness.n.01 ['fatness', 'fat', 'blubber', 'avoirdupois']\n",
      "fact\n",
      "['fact.n.01', 'fact.n.02', 'fact.n.03', 'fact.n.04']\n",
      "fact.n.01 ['fact']\n",
      "fact.n.02 ['fact']\n",
      "fact.n.03 ['fact']\n",
      "fact.n.04 ['fact']\n",
      "family\n",
      "['family.n.01', 'family.n.02', 'class.n.01', 'family.n.04', 'kin.n.01', 'family.n.06', 'syndicate.n.01', 'family.n.08']\n",
      "family.n.01 ['family', 'household', 'house', 'home', 'menage']\n",
      "family.n.02 ['family', 'family_unit']\n",
      "class.n.01 ['class', 'category', 'family']\n",
      "family.n.04 ['family', 'family_line', 'folk', 'kinfolk', 'kinsfolk', 'sept', 'phratry']\n",
      "kin.n.01 ['kin', 'kinsperson', 'family']\n",
      "family.n.06 ['family']\n",
      "syndicate.n.01 ['syndicate', 'crime_syndicate', 'mob', 'family']\n",
      "family.n.08 ['family', 'fellowship']\n",
      "government\n",
      "['government.n.01', 'government.n.02', 'government.n.03', 'politics.n.02']\n",
      "government.n.01 ['government', 'authorities', 'regime']\n",
      "government.n.02 ['government', 'governing', 'governance', 'government_activity', 'administration']\n",
      "government.n.03 ['government']\n",
      "politics.n.02 ['politics', 'political_science', 'government']\n",
      "group\n",
      "['group.n.01', 'group.n.02', 'group.n.03']\n",
      "group.n.01 ['group', 'grouping']\n",
      "group.n.02 ['group', 'radical', 'chemical_group']\n",
      "group.n.03 ['group', 'mathematical_group']\n",
      "hand\n",
      "['hand.n.01', 'hired_hand.n.01', 'handwriting.n.01', 'hand.n.04', 'hand.n.05', 'hand.n.06', 'hand.n.07', 'hand.n.08', 'hand.n.09', 'hand.n.10', 'bridge_player.n.01', 'hand.n.12', 'hand.n.13', 'hand.n.14']\n",
      "hand.n.01 ['hand', 'manus', 'mitt', 'paw']\n",
      "hired_hand.n.01 ['hired_hand', 'hand', 'hired_man']\n",
      "handwriting.n.01 ['handwriting', 'hand', 'script']\n",
      "hand.n.04 ['hand']\n",
      "hand.n.05 ['hand']\n",
      "hand.n.06 ['hand', 'deal']\n",
      "hand.n.07 ['hand']\n",
      "hand.n.08 ['hand']\n",
      "hand.n.09 ['hand']\n",
      "hand.n.10 ['hand']\n",
      "bridge_player.n.01 ['bridge_player', 'hand']\n",
      "hand.n.12 ['hand']\n",
      "hand.n.13 ['hand']\n",
      "hand.n.14 ['hand', 'helping_hand']\n",
      "home\n",
      "['home.n.01', 'dwelling.n.01', 'home.n.03', 'home_plate.n.01', 'base.n.14', 'home.n.06', 'home.n.07', 'family.n.01', 'home.n.09']\n",
      "home.n.01 ['home', 'place']\n",
      "dwelling.n.01 ['dwelling', 'home', 'domicile', 'abode', 'habitation', 'dwelling_house']\n",
      "home.n.03 ['home']\n",
      "home_plate.n.01 ['home_plate', 'home_base', 'home', 'plate']\n",
      "base.n.14 ['base', 'home']\n",
      "home.n.06 ['home']\n",
      "home.n.07 ['home']\n",
      "family.n.01 ['family', 'household', 'house', 'home', 'menage']\n",
      "home.n.09 ['home', 'nursing_home', 'rest_home']\n",
      "happiness\n",
      "['happiness.n.01', 'happiness.n.02']\n",
      "happiness.n.01 ['happiness', 'felicity']\n",
      "happiness.n.02 ['happiness']\n",
      "income\n",
      "['income.n.01']\n",
      "income.n.01 ['income']\n",
      "investment\n",
      "['investing.n.01', 'investment.n.02', 'investment.n.03', 'investment.n.04', 'investment.n.05', 'investment.n.06']\n",
      "investing.n.01 ['investing', 'investment']\n",
      "investment.n.02 ['investment', 'investment_funds']\n",
      "investment.n.03 ['investment']\n",
      "investment.n.04 ['investment']\n",
      "investment.n.05 ['investment']\n",
      "investment.n.06 ['investment', 'investiture']\n",
      "indication\n",
      "['indication.n.01', 'indication.n.02', 'indication.n.03', 'indication.n.04', 'reading.n.03']\n",
      "indication.n.01 ['indication', 'indicant']\n",
      "indication.n.02 ['indication', 'denotation']\n",
      "indication.n.03 ['indication']\n",
      "indication.n.04 ['indication']\n",
      "reading.n.03 ['reading', 'meter_reading', 'indication']\n",
      "intention\n",
      "['purpose.n.01', 'intention.n.02', 'intention.n.03']\n",
      "purpose.n.01 ['purpose', 'intent', 'intention', 'aim', 'design']\n",
      "intention.n.02 ['intention']\n",
      "intention.n.03 ['intention']\n",
      "job\n",
      "['occupation.n.01', 'job.n.02', 'job.n.03', 'job.n.04', 'job.n.05', 'job.n.06', 'job.n.07', 'problem.n.01', 'job.n.09', 'job.n.10', 'job.n.11', 'job.n.12', 'caper.n.03']\n",
      "occupation.n.01 ['occupation', 'business', 'job', 'line_of_work', 'line']\n",
      "job.n.02 ['job', 'task', 'chore']\n",
      "job.n.03 ['job']\n",
      "job.n.04 ['job']\n",
      "job.n.05 ['job']\n",
      "job.n.06 ['job']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job.n.07 ['job']\n",
      "problem.n.01 ['problem', 'job']\n",
      "job.n.09 ['Job']\n",
      "job.n.10 ['Job']\n",
      "job.n.11 ['job']\n",
      "job.n.12 ['Job', 'Book_of_Job']\n",
      "caper.n.03 ['caper', 'job']\n",
      "kayak\n",
      "['kayak.n.01']\n",
      "kayak.n.01 ['kayak']\n",
      "king\n",
      "['king.n.01', 'king.n.02', 'baron.n.03', 'king.n.04', 'king.n.05', 'king.n.06', 'king.n.07', 'king.n.08', 'king.n.09', 'king.n.10']\n",
      "king.n.01 ['king', 'male_monarch', 'Rex']\n",
      "king.n.02 ['king', 'queen', 'world-beater']\n",
      "baron.n.03 ['baron', 'big_businessman', 'business_leader', 'king', 'magnate', 'mogul', 'power', 'top_executive', 'tycoon']\n",
      "king.n.04 ['king']\n",
      "king.n.05 ['King', 'Billie_Jean_King', 'Billie_Jean_Moffitt_King']\n",
      "king.n.06 ['King', 'B._B._King', 'Riley_B_King']\n",
      "king.n.07 ['King', 'Martin_Luther_King', 'Martin_Luther_King_Jr.']\n",
      "king.n.08 ['king']\n",
      "king.n.09 ['king']\n",
      "king.n.10 ['king']\n",
      "life\n",
      "['life.n.01', 'life.n.02', 'life.n.03', 'animation.n.01', 'life.n.05', 'life.n.06', 'life.n.07', 'life.n.08', 'liveliness.n.02', 'life.n.10', 'life.n.11', 'biography.n.01', 'life.n.13', 'life_sentence.n.01']\n",
      "life.n.01 ['life']\n",
      "life.n.02 ['life', 'living']\n",
      "life.n.03 ['life']\n",
      "animation.n.01 ['animation', 'life', 'living', 'aliveness']\n",
      "life.n.05 ['life', 'lifetime', 'life-time', 'lifespan']\n",
      "life.n.06 ['life']\n",
      "life.n.07 ['life']\n",
      "life.n.08 ['life']\n",
      "liveliness.n.02 ['liveliness', 'life', 'spirit', 'sprightliness']\n",
      "life.n.10 ['life']\n",
      "life.n.11 ['life']\n",
      "biography.n.01 ['biography', 'life', 'life_story', 'life_history']\n",
      "life.n.13 ['life']\n",
      "life_sentence.n.01 ['life_sentence', 'life']\n",
      "lake\n",
      "['lake.n.01', 'lake.n.02', 'lake.n.03']\n",
      "lake.n.01 ['lake']\n",
      "lake.n.02 ['lake']\n",
      "lake.n.03 ['lake']\n",
      "love\n",
      "['love.n.01', 'love.n.02', 'beloved.n.01', 'love.n.04', 'love.n.05', 'sexual_love.n.02']\n",
      "love.n.01 ['love']\n",
      "love.n.02 ['love', 'passion']\n",
      "beloved.n.01 ['beloved', 'dear', 'dearest', 'honey', 'love']\n",
      "love.n.04 ['love', 'sexual_love', 'erotic_love']\n",
      "love.n.05 ['love']\n",
      "sexual_love.n.02 ['sexual_love', 'lovemaking', 'making_love', 'love', 'love_life']\n",
      "lot\n",
      "['batch.n.02', 'lot.n.02', 'set.n.05', 'fortune.n.04', 'draw.n.04', 'bunch.n.03', 'lot.n.07']\n",
      "batch.n.02 ['batch', 'deal', 'flock', 'good_deal', 'great_deal', 'hatful', 'heap', 'lot', 'mass', 'mess', 'mickle', 'mint', 'mountain', 'muckle', 'passel', 'peck', 'pile', 'plenty', 'pot', 'quite_a_little', 'raft', 'sight', 'slew', 'spate', 'stack', 'tidy_sum', 'wad']\n",
      "lot.n.02 ['lot']\n",
      "set.n.05 ['set', 'circle', 'band', 'lot']\n",
      "fortune.n.04 ['fortune', 'destiny', 'fate', 'luck', 'lot', 'circumstances', 'portion']\n",
      "draw.n.04 ['draw', 'lot']\n",
      "bunch.n.03 ['bunch', 'lot', 'caboodle']\n",
      "lot.n.07 ['Lot']\n",
      "man\n",
      "['man.n.01', 'serviceman.n.01', 'man.n.03', 'homo.n.02', 'man.n.05', 'man.n.06', 'valet.n.01', 'man.n.08', 'man.n.09', 'man.n.10', 'world.n.08']\n",
      "man.n.01 ['man', 'adult_male']\n",
      "serviceman.n.01 ['serviceman', 'military_man', 'man', 'military_personnel']\n",
      "man.n.03 ['man']\n",
      "homo.n.02 ['homo', 'man', 'human_being', 'human']\n",
      "man.n.05 ['man']\n",
      "man.n.06 ['man']\n",
      "valet.n.01 ['valet', 'valet_de_chambre', 'gentleman', \"gentleman's_gentleman\", 'man']\n",
      "man.n.08 ['man']\n",
      "man.n.09 ['Man', 'Isle_of_Man']\n",
      "man.n.10 ['man', 'piece']\n",
      "world.n.08 ['world', 'human_race', 'humanity', 'humankind', 'human_beings', 'humans', 'mankind', 'man']\n",
      "money\n",
      "['money.n.01', 'money.n.02', 'money.n.03']\n",
      "money.n.01 ['money']\n",
      "money.n.02 ['money']\n",
      "money.n.03 ['money']\n",
      "month\n",
      "['calendar_month.n.01', 'month.n.02']\n",
      "calendar_month.n.01 ['calendar_month', 'month']\n",
      "month.n.02 ['month']\n",
      "mother\n",
      "['mother.n.01', 'mother.n.02', 'mother.n.03', 'mother.n.04', 'mother.n.05']\n",
      "mother.n.01 ['mother', 'female_parent']\n",
      "mother.n.02 ['mother']\n",
      "mother.n.03 ['mother']\n",
      "mother.n.04 ['mother']\n",
      "mother.n.05 ['mother']\n",
      "night\n",
      "['night.n.01', 'night.n.02', 'night.n.03', 'night.n.04', 'night.n.05', 'night.n.06', 'night.n.07', 'nox.n.01']\n",
      "night.n.01 ['night', 'nighttime', 'dark']\n",
      "night.n.02 ['night']\n",
      "night.n.03 ['night']\n",
      "night.n.04 ['night']\n",
      "night.n.05 ['night']\n",
      "night.n.06 ['night']\n",
      "night.n.07 ['night']\n",
      "nox.n.01 ['Nox', 'Night']\n",
      "number\n",
      "['number.n.01', 'number.n.02', 'act.n.04', 'phone_number.n.01', 'numeral.n.01', 'issue.n.02', 'number.n.07', 'number.n.08', 'number.n.09', 'number.n.10', 'number.n.11']\n",
      "number.n.01 ['number', 'figure']\n",
      "number.n.02 ['number']\n",
      "act.n.04 ['act', 'routine', 'number', 'turn', 'bit']\n",
      "phone_number.n.01 ['phone_number', 'telephone_number', 'number']\n",
      "numeral.n.01 ['numeral', 'number']\n",
      "issue.n.02 ['issue', 'number']\n",
      "number.n.07 ['number']\n",
      "number.n.08 ['number', 'identification_number']\n",
      "number.n.09 ['number']\n",
      "number.n.10 ['number']\n",
      "number.n.11 ['number']\n",
      "offer\n",
      "['offer.n.01', 'offer.n.02', 'crack.n.09']\n",
      "offer.n.01 ['offer', 'offering']\n",
      "offer.n.02 ['offer', 'offering']\n",
      "crack.n.09 ['crack', 'fling', 'go', 'pass', 'whirl', 'offer']\n",
      "people\n",
      "['people.n.01', 'citizenry.n.01', 'people.n.03', 'multitude.n.03']\n",
      "people.n.01 ['people']\n",
      "citizenry.n.01 ['citizenry', 'people']\n",
      "people.n.03 ['people']\n",
      "multitude.n.03 ['multitude', 'masses', 'mass', 'hoi_polloi', 'people', 'the_great_unwashed']\n",
      "place\n",
      "['topographic_point.n.01', 'place.n.02', 'place.n.03', 'place.n.04', 'stead.n.01', 'place.n.06', 'home.n.01', 'position.n.06', 'position.n.01', 'place.n.10', 'seat.n.01', 'place.n.12', 'place.n.13', 'plaza.n.01', 'place.n.15', 'space.n.07']\n",
      "topographic_point.n.01 ['topographic_point', 'place', 'spot']\n",
      "place.n.02 ['place', 'property']\n",
      "place.n.03 ['place']\n",
      "place.n.04 ['place']\n",
      "stead.n.01 ['stead', 'position', 'place', 'lieu']\n",
      "place.n.06 ['place', 'shoes']\n",
      "home.n.01 ['home', 'place']\n",
      "position.n.06 ['position', 'post', 'berth', 'office', 'spot', 'billet', 'place', 'situation']\n",
      "position.n.01 ['position', 'place']\n",
      "place.n.10 ['place', 'station']\n",
      "seat.n.01 ['seat', 'place']\n",
      "place.n.12 ['place']\n",
      "place.n.13 ['place']\n",
      "plaza.n.01 ['plaza', 'place', 'piazza']\n",
      "place.n.15 ['place', 'position']\n",
      "space.n.07 ['space', 'blank_space', 'place']\n",
      "problem\n",
      "['problem.n.01', 'problem.n.02', 'trouble.n.01']\n",
      "problem.n.01 ['problem', 'job']\n",
      "problem.n.02 ['problem']\n",
      "trouble.n.01 ['trouble', 'problem']\n",
      "photograph\n",
      "['photograph.n.01']\n",
      "photograph.n.01 ['photograph', 'photo', 'exposure', 'picture', 'pic']\n",
      "priority\n",
      "['precedence.n.01', 'priority.n.02']\n",
      "precedence.n.01 ['precedence', 'precedency', 'priority']\n",
      "priority.n.02 ['priority', 'antecedence', 'antecedency', 'anteriority', 'precedence', 'precedency']\n",
      "question\n",
      "['question.n.01', 'question.n.02', 'question.n.03', 'doubt.n.02', 'motion.n.05', 'question.n.06']\n",
      "question.n.01 ['question', 'inquiry', 'enquiry', 'query', 'interrogation']\n",
      "question.n.02 ['question', 'head']\n",
      "question.n.03 ['question', 'interrogation', 'interrogative', 'interrogative_sentence']\n",
      "doubt.n.02 ['doubt', 'dubiousness', 'doubtfulness', 'question']\n",
      "motion.n.05 ['motion', 'question']\n",
      "question.n.06 ['question']\n",
      "right\n",
      "['right.n.01', 'right.n.02', 'right_field.n.01', 'right.n.04', 'right.n.05', 'right.n.06', 'right.n.07', 'right.n.08']\n",
      "right.n.01 ['right']\n",
      "right.n.02 ['right']\n",
      "right_field.n.01 ['right_field', 'rightfield', 'right']\n",
      "right.n.04 ['right', 'right_wing']\n",
      "right.n.05 ['right', 'right_hand']\n",
      "right.n.06 ['right']\n",
      "right.n.07 ['right', 'rightfulness']\n",
      "right.n.08 ['right']\n",
      "reality\n",
      "['world.n.03', 'reality.n.02', 'reality.n.03', 'reality.n.04']\n",
      "world.n.03 ['world', 'reality']\n",
      "reality.n.02 ['reality', 'realness', 'realism']\n",
      "reality.n.03 ['reality']\n",
      "reality.n.04 ['reality']\n",
      "relation\n",
      "['relation.n.01', 'sexual_intercourse.n.01', 'relative.n.01', 'relation.n.04', 'relation_back.n.01', 'relation.n.06']\n",
      "relation.n.01 ['relation']\n",
      "sexual_intercourse.n.01 ['sexual_intercourse', 'intercourse', 'sex_act', 'copulation', 'coitus', 'coition', 'sexual_congress', 'congress', 'sexual_relation', 'relation', 'carnal_knowledge']\n",
      "relative.n.01 ['relative', 'relation']\n",
      "relation.n.04 ['relation', 'telling', 'recounting']\n",
      "relation_back.n.01 ['relation_back', 'relation']\n",
      "relation.n.06 ['relation']\n",
      "revolution\n",
      "['revolution.n.01', 'revolution.n.02', 'rotation.n.03']\n",
      "revolution.n.01 ['revolution']\n",
      "revolution.n.02 ['revolution']\n",
      "rotation.n.03 ['rotation', 'revolution', 'gyration']\n",
      "replacement\n",
      "['replacement.n.01', 'surrogate.n.01', 'substitution.n.01', 'substitute.n.01', 'refilling.n.01', 'successor.n.01']\n",
      "replacement.n.01 ['replacement', 'replacing']\n",
      "surrogate.n.01 ['surrogate', 'alternate', 'replacement']\n",
      "substitution.n.01 ['substitution', 'permutation', 'transposition', 'replacement', 'switch']\n",
      "substitute.n.01 ['substitute', 'replacement']\n",
      "refilling.n.01 ['refilling', 'replenishment', 'replacement', 'renewal']\n",
      "successor.n.01 ['successor', 'replacement']\n",
      "resource\n",
      "['resource.n.01', 'resource.n.02', 'resource.n.03']\n",
      "resource.n.01 ['resource']\n",
      "resource.n.02 ['resource']\n",
      "resource.n.03 ['resource', 'resourcefulness', 'imagination']\n",
      "recommendation\n",
      "['recommendation.n.01', 'recommendation.n.02', 'recommendation.n.03']\n",
      "recommendation.n.01 ['recommendation']\n",
      "recommendation.n.02 ['recommendation', 'testimonial', 'good_word']\n",
      "recommendation.n.03 ['recommendation', 'passport']\n",
      "room\n",
      "['room.n.01', 'room.n.02', 'room.n.03', 'room.n.04']\n",
      "room.n.01 ['room']\n",
      "room.n.02 ['room', 'way', 'elbow_room']\n",
      "room.n.03 ['room']\n",
      "room.n.04 ['room']\n",
      "school\n",
      "['school.n.01', 'school.n.02', 'school.n.03', 'school.n.04', 'school.n.05', 'school.n.06', 'school.n.07']\n",
      "school.n.01 ['school']\n",
      "school.n.02 ['school', 'schoolhouse']\n",
      "school.n.03 ['school', 'schooling']\n",
      "school.n.04 ['school']\n",
      "school.n.05 ['school', 'schooltime', 'school_day']\n",
      "school.n.06 ['school']\n",
      "school.n.07 ['school', 'shoal']\n",
      "state\n",
      "['state.n.01', 'state.n.02', 'state.n.03', 'state.n.04', 'state_of_matter.n.01', 'state.n.06', 'country.n.02', 'department_of_state.n.01']\n",
      "state.n.01 ['state', 'province']\n",
      "state.n.02 ['state']\n",
      "state.n.03 ['state']\n",
      "state.n.04 ['state', 'nation', 'country', 'land', 'commonwealth', 'res_publica', 'body_politic']\n",
      "state_of_matter.n.01 ['state_of_matter', 'state']\n",
      "state.n.06 ['state']\n",
      "country.n.02 ['country', 'state', 'land']\n",
      "department_of_state.n.01 ['Department_of_State', 'United_States_Department_of_State', 'State_Department', 'State', 'DoS']\n",
      "story\n",
      "['narrative.n.01', 'story.n.02', 'floor.n.02', 'history.n.02', 'report.n.03', 'fib.n.01']\n",
      "narrative.n.01 ['narrative', 'narration', 'story', 'tale']\n",
      "story.n.02 ['story']\n",
      "floor.n.02 ['floor', 'level', 'storey', 'story']\n",
      "history.n.02 ['history', 'account', 'chronicle', 'story']\n",
      "report.n.03 ['report', 'news_report', 'story', 'account', 'write_up']\n",
      "fib.n.01 ['fib', 'story', 'tale', 'tarradiddle', 'taradiddle']\n",
      "student\n",
      "['student.n.01', 'scholar.n.01']\n",
      "student.n.01 ['student', 'pupil', 'educatee']\n",
      "scholar.n.01 ['scholar', 'scholarly_person', 'bookman', 'student']\n",
      "surgery\n",
      "['surgery.n.01', 'surgery.n.02', 'operating_room.n.01', 'operation.n.06']\n",
      "surgery.n.01 ['surgery']\n",
      "surgery.n.02 ['surgery']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operating_room.n.01 ['operating_room', 'OR', 'operating_theater', 'operating_theatre', 'surgery']\n",
      "operation.n.06 ['operation', 'surgery', 'surgical_operation', 'surgical_procedure', 'surgical_process']\n",
      "sympathy\n",
      "['sympathy.n.01', 'sympathy.n.02', 'sympathy.n.03']\n",
      "sympathy.n.01 ['sympathy', 'understanding']\n",
      "sympathy.n.02 ['sympathy', 'fellow_feeling']\n",
      "sympathy.n.03 ['sympathy']\n",
      "system\n",
      "['system.n.01', 'system.n.02', 'system.n.03', 'system.n.04', 'arrangement.n.03', 'system.n.06', 'system.n.07', 'system.n.08', 'organization.n.05']\n",
      "system.n.01 ['system']\n",
      "system.n.02 ['system', 'scheme']\n",
      "system.n.03 ['system']\n",
      "system.n.04 ['system', 'system_of_rules']\n",
      "arrangement.n.03 ['arrangement', 'organization', 'organisation', 'system']\n",
      "system.n.06 ['system']\n",
      "system.n.07 ['system']\n",
      "system.n.08 ['system']\n",
      "organization.n.05 ['organization', 'organisation', 'system']\n",
      "tension\n",
      "['tension.n.01', 'tension.n.02', 'tension.n.03', 'tension.n.04', 'latent_hostility.n.01', 'tension.n.06']\n",
      "tension.n.01 ['tension', 'tenseness', 'stress']\n",
      "tension.n.02 ['tension', 'tensity', 'tenseness', 'tautness']\n",
      "tension.n.03 ['tension']\n",
      "tension.n.04 ['tension']\n",
      "latent_hostility.n.01 ['latent_hostility', 'tension']\n",
      "tension.n.06 ['tension']\n",
      "thing\n",
      "['thing.n.01', 'thing.n.02', 'thing.n.03', 'thing.n.04', 'thing.n.05', 'matter.n.01', 'thing.n.07', 'thing.n.08', 'thing.n.09', 'thing.n.10', 'thing.n.11', 'thing.n.12']\n",
      "thing.n.01 ['thing']\n",
      "thing.n.02 ['thing']\n",
      "thing.n.03 ['thing']\n",
      "thing.n.04 ['thing']\n",
      "thing.n.05 ['thing']\n",
      "matter.n.01 ['matter', 'affair', 'thing']\n",
      "thing.n.07 ['thing']\n",
      "thing.n.08 ['thing']\n",
      "thing.n.09 ['thing']\n",
      "thing.n.10 ['thing']\n",
      "thing.n.11 ['thing']\n",
      "thing.n.12 ['thing']\n",
      "thought\n",
      "['idea.n.01', 'thinking.n.01', 'thought.n.03', 'opinion.n.01']\n",
      "idea.n.01 ['idea', 'thought']\n",
      "thinking.n.01 ['thinking', 'thought', 'thought_process', 'cerebration', 'intellection', 'mentation']\n",
      "thought.n.03 ['thought']\n",
      "opinion.n.01 ['opinion', 'sentiment', 'persuasion', 'view', 'thought']\n",
      "time\n",
      "['time.n.01', 'time.n.02', 'time.n.03', 'time.n.04', 'time.n.05', 'time.n.06', 'clock_time.n.01', 'fourth_dimension.n.01', 'meter.n.04', 'prison_term.n.01']\n",
      "time.n.01 ['time', 'clip']\n",
      "time.n.02 ['time']\n",
      "time.n.03 ['time']\n",
      "time.n.04 ['time']\n",
      "time.n.05 ['time']\n",
      "time.n.06 ['time']\n",
      "clock_time.n.01 ['clock_time', 'time']\n",
      "fourth_dimension.n.01 ['fourth_dimension', 'time']\n",
      "meter.n.04 ['meter', 'metre', 'time']\n",
      "prison_term.n.01 ['prison_term', 'sentence', 'time']\n",
      "training\n",
      "['training.n.01', 'education.n.05']\n",
      "training.n.01 ['training', 'preparation', 'grooming']\n",
      "education.n.05 ['education', 'training', 'breeding']\n",
      "universe\n",
      "['universe.n.01', 'population.n.03', 'universe.n.03']\n",
      "universe.n.01 ['universe', 'existence', 'creation', 'world', 'cosmos', 'macrocosm']\n",
      "population.n.03 ['population', 'universe']\n",
      "universe.n.03 ['universe', 'universe_of_discourse']\n",
      "victim\n",
      "['victim.n.01', 'victim.n.02']\n",
      "victim.n.01 ['victim']\n",
      "victim.n.02 ['victim', 'dupe']\n",
      "way\n",
      "['manner.n.01', 'means.n.01', 'direction.n.01', 'way.n.04', 'way.n.05', 'way.n.06', 'way.n.07', 'room.n.02', 'way.n.09', 'way.n.10', 'way.n.11', 'way.n.12']\n",
      "manner.n.01 ['manner', 'mode', 'style', 'way', 'fashion']\n",
      "means.n.01 ['means', 'agency', 'way']\n",
      "direction.n.01 ['direction', 'way']\n",
      "way.n.04 ['way']\n",
      "way.n.05 ['way', 'path', 'way_of_life']\n",
      "way.n.06 ['way']\n",
      "way.n.07 ['way']\n",
      "room.n.02 ['room', 'way', 'elbow_room']\n",
      "way.n.09 ['way']\n",
      "way.n.10 ['way']\n",
      "way.n.11 ['way']\n",
      "way.n.12 ['way']\n",
      "wealth\n",
      "['wealth.n.01', 'wealth.n.02', 'wealth.n.03', 'wealth.n.04']\n",
      "wealth.n.01 ['wealth', 'wealthiness']\n",
      "wealth.n.02 ['wealth']\n",
      "wealth.n.03 ['wealth', 'riches']\n",
      "wealth.n.04 ['wealth']\n",
      "woman\n",
      "['woman.n.01', 'woman.n.02', 'charwoman.n.01', 'womanhood.n.02']\n",
      "woman.n.01 ['woman', 'adult_female']\n",
      "woman.n.02 ['woman']\n",
      "charwoman.n.01 ['charwoman', 'char', 'cleaning_woman', 'cleaning_lady', 'woman']\n",
      "womanhood.n.02 ['womanhood', 'woman', 'fair_sex']\n",
      "word\n",
      "['word.n.01', 'word.n.02', 'news.n.01', 'word.n.04', 'discussion.n.02', 'parole.n.01', 'word.n.07', 'son.n.02', 'password.n.01', 'bible.n.01']\n",
      "word.n.01 ['word']\n",
      "word.n.02 ['word']\n",
      "news.n.01 ['news', 'intelligence', 'tidings', 'word']\n",
      "word.n.04 ['word']\n",
      "discussion.n.02 ['discussion', 'give-and-take', 'word']\n",
      "parole.n.01 ['parole', 'word', 'word_of_honor']\n",
      "word.n.07 ['word']\n",
      "son.n.02 ['Son', 'Word', 'Logos']\n",
      "password.n.01 ['password', 'watchword', 'word', 'parole', 'countersign']\n",
      "bible.n.01 ['Bible', 'Christian_Bible', 'Book', 'Good_Book', 'Holy_Scripture', 'Holy_Writ', 'Scripture', 'Word_of_God', 'Word']\n",
      "work\n",
      "['work.n.01', 'work.n.02', 'employment.n.02', 'study.n.02', 'work.n.05', 'workplace.n.01', 'oeuvre.n.01']\n",
      "work.n.01 ['work']\n",
      "work.n.02 ['work', 'piece_of_work']\n",
      "employment.n.02 ['employment', 'work']\n",
      "study.n.02 ['study', 'work']\n",
      "work.n.05 ['work']\n",
      "workplace.n.01 ['workplace', 'work']\n",
      "oeuvre.n.01 ['oeuvre', 'work', 'body_of_work']\n",
      "world\n",
      "['universe.n.01', 'world.n.02', 'world.n.03', 'earth.n.01', 'populace.n.01', 'world.n.06', 'worldly_concern.n.01', 'world.n.08']\n",
      "universe.n.01 ['universe', 'existence', 'creation', 'world', 'cosmos', 'macrocosm']\n",
      "world.n.02 ['world', 'domain']\n",
      "world.n.03 ['world', 'reality']\n",
      "earth.n.01 ['Earth', 'earth', 'world', 'globe']\n",
      "populace.n.01 ['populace', 'public', 'world']\n",
      "world.n.06 ['world']\n",
      "worldly_concern.n.01 ['worldly_concern', 'earthly_concern', 'world', 'earth']\n",
      "world.n.08 ['world', 'human_race', 'humanity', 'humankind', 'human_beings', 'humans', 'mankind', 'man']\n",
      "year\n",
      "['year.n.01', 'year.n.02', 'year.n.03', 'class.n.06']\n",
      "year.n.01 ['year', 'twelvemonth', 'yr']\n",
      "year.n.02 ['year']\n",
      "year.n.03 ['year']\n",
      "class.n.06 ['class', 'year']\n",
      "inside\n",
      "['inside.n.01', 'inside.n.02']\n",
      "inside.n.01 ['inside', 'interior']\n",
      "inside.n.02 ['inside', 'interior']\n",
      "outside\n",
      "['outside.n.01', 'outside.n.02']\n",
      "outside.n.01 ['outside', 'exterior']\n",
      "outside.n.02 ['outside', 'exterior']\n",
      "medium\n",
      "['medium.n.01', 'medium.n.02', 'medium.n.03', 'culture_medium.n.01', 'medium.n.05', 'medium.n.06', 'medium.n.07', 'medium.n.08', 'medium.n.09', 'medium.n.10', 'metier.n.02']\n",
      "medium.n.01 ['medium']\n",
      "medium.n.02 ['medium']\n",
      "medium.n.03 ['medium']\n",
      "culture_medium.n.01 ['culture_medium', 'medium']\n",
      "medium.n.05 ['medium']\n",
      "medium.n.06 ['medium']\n",
      "medium.n.07 ['medium']\n",
      "medium.n.08 ['medium']\n",
      "medium.n.09 ['medium', 'spiritualist', 'sensitive']\n",
      "medium.n.10 ['medium', 'mass_medium']\n",
      "metier.n.02 ['metier', 'medium']\n",
      "item\n",
      "['item.n.01', 'detail.n.02', 'item.n.03', 'detail.n.01', 'token.n.01']\n",
      "item.n.01 ['item', 'point']\n",
      "detail.n.02 ['detail', 'particular', 'item']\n",
      "item.n.03 ['item']\n",
      "detail.n.01 ['detail', 'item', 'point']\n",
      "token.n.01 ['token', 'item']\n",
      "average\n",
      "['average.n.01', 'average.n.02', 'average.n.03']\n",
      "average.n.01 ['average', 'norm']\n",
      "average.n.02 ['average']\n",
      "average.n.03 ['average']\n",
      "feeling\n",
      "['feeling.n.01', 'impression.n.01', 'spirit.n.02', 'feeling.n.04', 'touch.n.10', 'feeling.n.06']\n",
      "feeling.n.01 ['feeling']\n",
      "impression.n.01 ['impression', 'feeling', 'belief', 'notion', 'opinion']\n",
      "spirit.n.02 ['spirit', 'tone', 'feel', 'feeling', 'flavor', 'flavour', 'look', 'smell']\n",
      "feeling.n.04 ['feeling']\n",
      "touch.n.10 ['touch', 'touch_sensation', 'tactual_sensation', 'tactile_sensation', 'feeling']\n",
      "feeling.n.06 ['feeling', 'intuitive_feeling']\n",
      "savings\n",
      "['savings.n.01', 'economy.n.04', 'rescue.n.01', 'preservation.n.01']\n",
      "savings.n.01 ['savings', 'nest_egg']\n",
      "economy.n.04 ['economy', 'saving']\n",
      "rescue.n.01 ['rescue', 'deliverance', 'delivery', 'saving']\n",
      "preservation.n.01 ['preservation', 'saving']\n",
      "edge\n",
      "['edge.n.01', 'boundary.n.02', 'edge.n.03', 'edge.n.04', 'edge.n.05', 'edge.n.06']\n",
      "edge.n.01 ['edge', 'border']\n",
      "boundary.n.02 ['boundary', 'edge', 'bound']\n",
      "edge.n.03 ['edge']\n",
      "edge.n.04 ['edge', 'sharpness']\n",
      "edge.n.05 ['edge']\n",
      "edge.n.06 ['edge']\n",
      "evidence\n",
      "['evidence.n.01', 'evidence.n.02', 'evidence.n.03']\n",
      "evidence.n.01 ['evidence', 'grounds']\n",
      "evidence.n.02 ['evidence']\n",
      "evidence.n.03 ['evidence']\n",
      "street\n",
      "['street.n.01', 'street.n.02', 'street.n.03', 'street.n.04', 'street.n.05']\n",
      "street.n.01 ['street']\n",
      "street.n.02 ['street']\n",
      "street.n.03 ['street']\n",
      "street.n.04 ['street']\n",
      "street.n.05 ['street']\n",
      "drop\n",
      "['drop.n.01', 'drop.n.02', 'drop.n.03', 'cliff.n.01', 'drop.n.05', 'drop.n.06', 'drop_curtain.n.01', 'drop.n.08', 'drop.n.09']\n",
      "drop.n.01 ['drop', 'bead', 'pearl']\n",
      "drop.n.02 ['drop', 'drib', 'driblet']\n",
      "drop.n.03 ['drop', 'dip', 'fall', 'free_fall']\n",
      "cliff.n.01 ['cliff', 'drop', 'drop-off']\n",
      "drop.n.05 ['drop']\n",
      "drop.n.06 ['drop', 'fall']\n",
      "drop_curtain.n.01 ['drop_curtain', 'drop_cloth', 'drop']\n",
      "drop.n.08 ['drop']\n",
      "drop.n.09 ['drop']\n",
      "substance\n",
      "['substance.n.01', 'kernel.n.03', 'meaning.n.02', 'substance.n.04', 'means.n.03', 'message.n.02', 'substance.n.07']\n",
      "substance.n.01 ['substance']\n",
      "kernel.n.03 ['kernel', 'substance', 'core', 'center', 'centre', 'essence', 'gist', 'heart', 'heart_and_soul', 'inwardness', 'marrow', 'meat', 'nub', 'pith', 'sum', 'nitty-gritty']\n",
      "meaning.n.02 ['meaning', 'substance']\n",
      "substance.n.04 ['substance']\n",
      "means.n.03 ['means', 'substance']\n",
      "message.n.02 ['message', 'content', 'subject_matter', 'substance']\n",
      "substance.n.07 ['substance']\n",
      "detail\n",
      "['detail.n.01', 'detail.n.02', 'detail.n.03', 'detail.n.04', 'contingent.n.02']\n",
      "detail.n.01 ['detail', 'item', 'point']\n",
      "detail.n.02 ['detail', 'particular', 'item']\n",
      "detail.n.03 ['detail']\n",
      "detail.n.04 ['detail']\n",
      "contingent.n.02 ['contingent', 'detail']\n",
      "agent\n",
      "['agent.n.01', 'agent.n.02', 'agent.n.03', 'agent.n.04', 'agent.n.05', 'agentive_role.n.01']\n",
      "agent.n.01 ['agent']\n",
      "agent.n.02 ['agent']\n",
      "agent.n.03 ['agent']\n",
      "agent.n.04 ['agent', 'factor', 'broker']\n",
      "agent.n.05 ['agent', 'federal_agent']\n",
      "agentive_role.n.01 ['agentive_role', 'agent']\n"
     ]
    }
   ],
   "source": [
    "for word in nouns:\n",
    "    syn_group = []\n",
    "    syn_dict = dict()\n",
    "    print(word)\n",
    "    for elem in wn.synsets(word, pos='n'):\n",
    "        syn_group.append(elem.name())\n",
    "    print(syn_group)\n",
    "    for elem in syn_group:\n",
    "        syn_dict[elem] = wn.synset(elem).lemma_names()\n",
    "        print(elem, syn_dict[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epic_jenoptik_venv",
   "language": "python",
   "name": "epic_jenoptik_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
